services:
  # TradeBuddy main application
  tradebuddy:
    build:
      context: .
      target: production
    container_name: tradebuddy-app
    restart: unless-stopped
    environment:
      - PYTHON_ENV=production
      - DELTA_API_KEY=${DELTA_API_KEY:-}
      - DELTA_API_SECRET=${DELTA_API_SECRET:-}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - FINGPT_API_ENDPOINT=${FINGPT_API_ENDPOINT:-http://fingpt-api:8000}
      - FINGPT_API_KEY=${FINGPT_API_KEY:-}
    volumes:
      - ./backtest_reports:/app/backtest_reports
      - ./logs:/app/logs
      - ./.env:/app/.env:ro
    networks:
      - tradebuddy-network
    depends_on:
      - ollama
    stdin_open: true
    tty: true

  # TradeBuddy development version
  tradebuddy-dev:
    build:
      context: .
      target: development
    container_name: tradebuddy-dev
    restart: "no"
    environment:
      - PYTHON_ENV=development
      - DEBUG=true
      - DELTA_API_KEY=${DELTA_API_KEY:-}
      - DELTA_API_SECRET=${DELTA_API_SECRET:-}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - FINGPT_API_ENDPOINT=${FINGPT_API_ENDPOINT:-http://fingpt-api:8000}
      - FINGPT_API_KEY=${FINGPT_API_KEY:-}
    volumes:
      - .:/app
      - ./backtest_reports:/app/backtest_reports
      - ./logs:/app/logs
    networks:
      - tradebuddy-network
    depends_on:
      - ollama
    stdin_open: true
    tty: true
    profiles:
      - dev

  # Ollama AI service
  ollama:
    image: ollama/ollama:latest
    container_name: tradebuddy-ollama
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11435:11434"
    networks:
      - tradebuddy-network
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G

  # FinGPT API service (production server with real models)
  fingpt-api:
    build:
      context: /Users/vrushabhbayas/fingpt-server
    container_name: tradebuddy-fingpt
    restart: unless-stopped
    environment:
      - FINGPT_MODEL_VARIANT=${FINGPT_MODEL_VARIANT:-v3.2}
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - TRANSFORMERS_CACHE=/app/model_cache
    volumes:
      - fingpt_models:/app/model_cache
    ports:
      - "8001:8000"
    networks:
      - tradebuddy-network
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 8G
    profiles:
      - fingpt

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: tradebuddy-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - tradebuddy-network
    profiles:
      - cache

  # Monitoring with Prometheus (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: tradebuddy-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    networks:
      - tradebuddy-network
    profiles:
      - monitoring

  # Grafana for visualization (optional)
  grafana:
    image: grafana/grafana:latest
    container_name: tradebuddy-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana:/etc/grafana/provisioning
    networks:
      - tradebuddy-network
    depends_on:
      - prometheus
    profiles:
      - monitoring

volumes:
  ollama_data:
    driver: local
  fingpt_models:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  tradebuddy-network:
    driver: bridge